{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import BobcatParser, stairs_reader, cups_reader\n",
    "from lambeq import AtomicType, IQPAnsatz\n",
    "from quantum_pipeline import *\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define atomic-types\n",
    "\n",
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "C = AtomicType.CONJUNCTION\n",
    "P = AtomicType.PUNCTUATION\n",
    "NP = AtomicType.NOUN_PHRASE\n",
    "PP = AtomicType.PREPOSITIONAL_PHRASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser = BobcatParser(root_cats = (\"NP\", \"N\"), verbose = \"progress\")\n",
    "ansatz = IQPAnsatz({N: 1, S: 1, C: 1, P: 1, NP: 1, PP: 1}, n_layers = 1, n_single_qubit_params = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = QuantumPipeline(stairs_reader, ansatz)\n",
    "#train_labels, train_circuits = pipeline.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/quantum/GPS_quantum.csv\")\n",
    "#test_labels, test_circuits = pipeline.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/quantum/CPN_quantum.csv\")\n",
    "#eval_labels, eval_circuits = pipeline.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/quantum/ePurse_quantum.csv\")\n",
    "\n",
    "#train_labels, train_circuits = pipeline.create_circuits_and_labels(\"C:\\\\Users\\\\calif\\\\Documents\\\\GitHub\\\\Tesi-Quantum-NLP\\\\project\\\\datasets\\\\edited_datasets\\\\quantum\\\\GPS_quantum.csv\")\n",
    "#test_labels, test_circuits = pipeline.create_circuits_and_labels(\"C:\\\\Users\\\\calif\\\\Documents\\\\GitHub\\\\Tesi-Quantum-NLP\\\\project\\\\datasets\\\\edited_datasets\\\\quantum\\\\CPN_quantum.csv\")\n",
    "#eval_labels, eval_circuits = pipeline.create_circuits_and_labels(\"C:\\\\Users\\\\calif\\\\Documents\\\\GitHub\\\\Tesi-Quantum-NLP\\\\project\\\\datasets\\\\edited_datasets\\\\quantum\\\\ePurse_quantum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset anthony\n",
    "\n",
    "pipeline = QuantumPipeline(stairs_reader, ansatz)\n",
    "train_labels, train_circuits = pipeline.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/dataset_training.csv\")\n",
    "eval_labels, eval_circuits = pipeline.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/dataset_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_data(\"quantum_train_data.txt\", train_labels, train_circuits)\n",
    "#save_data(\"quantum_test_data.txt\", test_labels, test_circuits)\n",
    "#save_data(\"quantum_eval_data.txt\", eval_labels, eval_circuits)\n",
    "\n",
    "train_labels, train_circuits = load_data(\"quantum_train_data.txt\")\n",
    "test_labels, test_circuits = load_data(\"quantum_test_data.txt\")\n",
    "eval_labels, eval_circuits = load_data(\"quantum_eval_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, eval_set = pipeline.create_dataset(train_circuits, train_labels), pipeline.create_dataset(test_circuits, test_labels), pipeline.create_dataset(eval_circuits, eval_labels)\n",
    "model = pipeline.create_model(train_circuits, test_circuits, eval_circuits)\n",
    "pipeline.create_trainer(model = model, n_epochs = 100, a_hyp = 0.03, evaluate = True)\n",
    "pipeline.train_and_evaluate(train_set, eval_set, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridsearch for quantum case\n",
    "epochs = [100]\n",
    "learning_rates = [3e-1, 3e-2, 3e-3]\n",
    "\n",
    "train_set, test_set, eval_set = pipeline.create_dataset(train_circuits, train_labels), pipeline.create_dataset(test_circuits, test_labels), pipeline.create_dataset(eval_circuits, eval_labels)\n",
    "model = pipeline.create_model(train_circuits, test_circuits, eval_circuits)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"Current learning rate: {str(lr)}\\n\")\n",
    "    pipeline.create_trainer(model = model, n_epochs = 100, a_hyp = lr, evaluate = True)\n",
    "    pipeline.train_and_evaluate(train_set, eval_set, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, eval_set = pipeline.create_dataset(train_circuits, train_labels), pipeline.create_dataset(test_circuits, test_labels), pipeline.create_dataset(eval_circuits, eval_labels)\n",
    "model = pipeline.create_model(train_circuits, test_circuits, eval_circuits)\n",
    "pipeline.create_trainer(model = model, n_epochs = 100, a_hyp = 3e-1, evaluate = True)\n",
    "pipeline.train_and_evaluate(train_set, eval_set, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, eval_set = pipeline.create_dataset(train_circuits, train_labels), pipeline.create_dataset(test_circuits, test_labels), pipeline.create_dataset(eval_circuits, eval_labels)\n",
    "model = pipeline.create_model(train_circuits, test_circuits, eval_circuits)\n",
    "pipeline.create_trainer(model = model, n_epochs = 100, a_hyp = 3e-2, evaluate = True)\n",
    "pipeline.train_and_evaluate(train_set, eval_set, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, eval_set = pipeline.create_dataset(train_circuits, train_labels), pipeline.create_dataset(test_circuits, test_labels), pipeline.create_dataset(eval_circuits, eval_labels)\n",
    "model = pipeline.create_model(train_circuits, test_circuits, eval_circuits)\n",
    "pipeline.create_trainer(model = model, n_epochs = 100, a_hyp = 3e-3, evaluate = True)\n",
    "pipeline.train_and_evaluate(train_set, eval_set, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1000 epoch training\n",
    "train_set, test_set, eval_set = pipeline.create_dataset(train_circuits, train_labels), pipeline.create_dataset(test_circuits, test_labels), pipeline.create_dataset(eval_circuits, eval_labels)\n",
    "model = pipeline.create_model(train_circuits, test_circuits, eval_circuits)\n",
    "pipeline.create_trainer(model = model, n_epochs = 1000, a_hyp = 3e-2, evaluate = True)\n",
    "\n",
    "model1 = pipeline.load_from_model(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/codice/runs/Jun28_20-34-21_archlinux\")\n",
    "pipeline.train_and_evaluate(train_set, eval_set, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from decimal import Decimal\n",
    "\n",
    "def extract(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    dictionary = {\n",
    "        \"train_loss\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"train_acc\" : [],\n",
    "        \"test_acc\" : [],\n",
    "        \"train_prec\": [],\n",
    "        \"test_prec\": [],\n",
    "        \"train_rec\" : [],\n",
    "        \"test_rec\" : [],\n",
    "        \"train_f1\" : [],\n",
    "        \"test_f1\" : []\n",
    "    }\n",
    "    \n",
    "    for line in file:\n",
    "        lista = line.split()\n",
    "        dictionary[\"train_loss\"] += [float(lista[3])]\n",
    "        dictionary[\"test_loss\"] += [float(lista[5])]\n",
    "        dictionary[\"train_acc\"] += [float(lista[7])]\n",
    "        dictionary[\"test_acc\"] += [float(lista[15])]\n",
    "        dictionary[\"train_prec\"] += [float(lista[9])]\n",
    "        dictionary[\"test_prec\"] += [float(lista[17])]\n",
    "        dictionary[\"train_rec\"] += [float(lista[11])]\n",
    "        dictionary[\"test_rec\"] += [float(lista[19])]\n",
    "        dictionary[\"train_f1\"] += [float(lista[13])]\n",
    "        dictionary[\"test_f1\"] += [float(lista[21])]\n",
    "        \n",
    "    return dictionary\n",
    "    \n",
    "def calculate_precision(f1, rec):\n",
    "    value =  - ((f1 * rec) / (f1 - 2*rec))\n",
    "    rounded = round(Decimal(value), 4)\n",
    "    return rounded\n",
    "    \n",
    "def add_precision(diz):\n",
    "    train_prec = []\n",
    "    test_prec = []\n",
    "    \n",
    "    for item1, item2 in zip(diz[\"train_rec\"], diz[\"train_f1\"]):\n",
    "        train_prec.append(calculate_precision(item2, item1))\n",
    "        \n",
    "    for item1, item2 in zip(diz[\"test_rec\"], diz[\"test_f1\"]):\n",
    "        test_prec.append(calculate_precision(item2, item1))\n",
    "        \n",
    "    diz[\"train_prec\"] = train_prec\n",
    "    diz[\"test_prec\"] = test_prec\n",
    "    \n",
    "    return diz\n",
    "    \n",
    "def plot_loss(dictionary):\n",
    "    x = [i for i in range(0, 1000, 1)]\n",
    "    figure, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 20))\n",
    "    \n",
    "    ax1.plot(x, dictionary[\"train_loss\"], label = \"train loss\")\n",
    "    ax2.plot(x, dictionary[\"test_loss\"], label = \"test loss\", color = \"orange\")\n",
    "    \n",
    "    ax1.legend(loc = 'upper right'), ax2.legend(loc = 'upper right')\n",
    "    ax1.set_xticks([x for x in range(0, 105, 5)]), ax2.set_xticks([x for x in range(0, 105, 5)])\n",
    "    ax1.set_yticks([y/100 for y in range(0, 100, 5)]), ax2.set_yticks([y/100 for y in range(0, 100, 5)])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_data(dictionary):\n",
    "    x = [i for i in range(0, 1000, 1)]\n",
    "    figure, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 12))\n",
    "  \n",
    "    ax1.plot(x, dictionary[\"train_acc\"], label = \"train accuracy\")\n",
    "    ax1.plot(x, dictionary[\"test_acc\"], label = \"test accuracy\", color = \"orange\")\n",
    "    ax4.plot(x, dictionary[\"train_prec\"], label = \"train precision\")\n",
    "    ax4.plot(x, dictionary[\"test_prec\"], label = \"test precision\", color = \"orange\")\n",
    "    ax2.plot(x, dictionary[\"train_rec\"], label = \"train recall\")\n",
    "    ax2.plot(x, dictionary[\"test_rec\"], label = \"test recall\", color = \"orange\")\n",
    "    ax3.plot(x, dictionary[\"train_f1\"], label = \"train f1\")\n",
    "    ax3.plot(x, dictionary[\"test_f1\"], label = \"test f1\", color = \"orange\")       \n",
    "    \n",
    "    ax1.legend(loc = 'upper right'), ax2.legend(loc = 'upper right'), ax3.legend(loc = 'upper right'), ax4.legend(loc = 'lower right')\n",
    "    ax1.set_xticks([x for x in range(0, 1100, 100)]), ax2.set_xticks([x for x in range(0, 1100, 100)]), ax3.set_xticks([x for x in range(0, 1100, 100)]), ax4.set_xticks([x for x in range(0, 1100, 100)])     \n",
    "    ax1.set_yticks([y / 100 for y in range(0, 90, 5)]), ax2.set_yticks([y / 100 for y in range(0, 90, 5)]), ax3.set_yticks([y / 100 for y in range(0, 90, 5)]), ax4.set_yticks([y / 100 for y in range(0, 90, 5)])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz = extract(\"plot.txt\") \n",
    "plot_data(diz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
