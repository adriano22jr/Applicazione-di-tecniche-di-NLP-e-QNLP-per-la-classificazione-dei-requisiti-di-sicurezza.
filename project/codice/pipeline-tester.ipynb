{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import BobcatParser, TreeReader, TreeReaderMode, spiders_reader, cups_reader, stairs_reader\n",
    "from lambeq import TensorAnsatz, SpiderAnsatz, MPSAnsatz, IQPAnsatz, AtomicType\n",
    "from discopy import Dim\n",
    "from classic_pipeline import *\n",
    "from quantum_pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser declaration\n",
    "\n",
    "bobcat_parser = BobcatParser(verbose = \"progress\")\n",
    "spider_parser = spiders_reader\n",
    "cups_parser = cups_reader\n",
    "stairs_parser = stairs_reader\n",
    "tree_parser = TreeReader(mode=TreeReaderMode.RULE_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ansatze declaration\n",
    "\n",
    "tensor_ansatz = TensorAnsatz({AtomicType.NOUN: Dim(2), AtomicType.SENTENCE: Dim(2), AtomicType.CONJUNCTION: Dim(2), AtomicType.PUNCTUATION: Dim(2), AtomicType.NOUN_PHRASE: Dim(2), AtomicType.PREPOSITIONAL_PHRASE: Dim(2)})\n",
    "spider_ansatz = SpiderAnsatz({AtomicType.NOUN: Dim(2), AtomicType.SENTENCE: Dim(2)})\n",
    "mps_ansatz = MPSAnsatz({AtomicType.NOUN: Dim(2), AtomicType.SENTENCE: Dim(2)}, bond_dim = 3)\n",
    "iqp_ansatz = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 0}, n_layers = 1, n_single_qubit_params = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cbb7191fd64c51bd05c290474fec19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing tagged sentences:   0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a7888253274c6f9168bba8ed3ac17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parse trees to diagrams:   0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data-extracion for classic pipeline\n",
    "\n",
    "pip = ClassicPipeline(bobcat_parser, tensor_ansatz)\n",
    "pip.add_rewriter_rules(ClassicPipeline.SUPPORTED_RULES[0], ClassicPipeline.SUPPORTED_RULES[1], ClassicPipeline.SUPPORTED_RULES[4])\n",
    "train_labels, train_circuits = pip.create_circuits_and_labels(\"C:\\\\Users\\\\calif\\\\Documents\\\\GitHub\\\\Tesi-Quantum-NLP\\\\project\\\\datasets\\\\edited_datasets\\\\GPS_edited.csv\", \"n\")\n",
    "test_labels, test_circuits = pip.create_circuits_and_labels(\"C:\\\\Users\\\\calif\\\\Documents\\\\GitHub\\\\Tesi-Quantum-NLP\\\\project\\\\datasets\\\\edited_datasets\\\\ePurse_edited.csv\", \"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2] at entry 0 and [2, 2] at entry 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m train_set, test_set \u001b[39m=\u001b[39m pip\u001b[39m.\u001b[39mcreate_dataset(train_labels, train_circuits), pip\u001b[39m.\u001b[39mcreate_dataset(test_labels, test_circuits)\n\u001b[0;32m      2\u001b[0m pip\u001b[39m.\u001b[39mcreate_trainer(train_circuits, test_circuits)\n\u001b[1;32m----> 3\u001b[0m pip\u001b[39m.\u001b[39;49mtrain_model(train_set, test_set)\n\u001b[0;32m      4\u001b[0m \u001b[39m#pip.plot()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\calif\\Documents\\GitHub\\Tesi-Quantum-NLP\\project\\codice\\classic_pipeline.py:63\u001b[0m, in \u001b[0;36mClassicPipeline.train_model\u001b[1;34m(self, train_set, test_set)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(\u001b[39mself\u001b[39m, train_set, test_set):        \n\u001b[1;32m---> 63\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__trainer\u001b[39m.\u001b[39;49mfit(train_set, test_set, evaluation_step \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, logging_step \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lambeq\\training\\trainer.py:374\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, train_dataset, val_dataset, evaluation_step, logging_step)\u001b[0m\n\u001b[0;32m    372\u001b[0m step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    373\u001b[0m x, y_label \u001b[39m=\u001b[39m batch\n\u001b[1;32m--> 374\u001b[0m y_hat, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(batch)\n\u001b[0;32m    375\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate_on_train\n\u001b[0;32m    376\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate_functions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    377\u001b[0m     \u001b[39mfor\u001b[39;00m metr, func \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate_functions\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lambeq\\training\\pytorch_trainer.py:201\u001b[0m, in \u001b[0;36mPytorchTrainer.training_step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Perform a training step.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \n\u001b[0;32m    199\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m x, y \u001b[39m=\u001b[39m batch\n\u001b[1;32m--> 201\u001b[0m y_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[0;32m    202\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_function(y_hat, y\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice))\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_costs\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lambeq\\training\\model.py:57\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lambeq\\training\\pytorch_model.py:157\u001b[0m, in \u001b[0;36mPytorchModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: \u001b[39mlist\u001b[39m[Diagram]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m    140\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Perform default forward pass by contracting tensors.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \n\u001b[0;32m    142\u001b[0m \u001b[39m    In case of a different datapoint (e.g. list of tuple) or\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_diagram_output(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lambeq\\training\\pytorch_model.py:136\u001b[0m, in \u001b[0;36mPytorchModel.get_diagram_output\u001b[1;34m(self, diagrams)\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnknown symbol \u001b[39m\u001b[39m{\u001b[39;00mb\u001b[39m.\u001b[39m_data\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    135\u001b[0m \u001b[39mwith\u001b[39;00m Tensor\u001b[39m.\u001b[39mbackend(\u001b[39m'\u001b[39m\u001b[39mpytorch\u001b[39m\u001b[39m'\u001b[39m), tn\u001b[39m.\u001b[39mDefaultBackend(\u001b[39m'\u001b[39m\u001b[39mpytorch\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 136\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(\n\u001b[0;32m    137\u001b[0m         [tn\u001b[39m.\u001b[39;49mcontractors\u001b[39m.\u001b[39;49mauto(\u001b[39m*\u001b[39;49md\u001b[39m.\u001b[39;49mto_tn())\u001b[39m.\u001b[39;49mtensor \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m diagrams])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [2] at entry 0 and [2, 2] at entry 2"
     ]
    }
   ],
   "source": [
    "train_set, test_set = pip.create_dataset(train_labels, train_circuits), pip.create_dataset(test_labels, test_circuits)\n",
    "pip.create_trainer(train_circuits, test_circuits)\n",
    "pip.train_model(train_set, test_set)\n",
    "#pip.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data-extracion for quantum pipeline\n",
    "\n",
    "pip = QuantumPipeline(bobcat_parser, iqp_ansatz)\n",
    "train_labels, train_circuits = pip.create_circuits_and_labels(\"code/pipeline/rp_train_data.txt\")\n",
    "test_labels, test_circuits = pip.create_circuits_and_labels(\"code/pipeline/rp_test_data.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
