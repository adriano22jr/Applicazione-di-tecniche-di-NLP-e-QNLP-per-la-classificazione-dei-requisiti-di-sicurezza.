{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo docker run --gpus all -p 8888:8888 -it --rm tensorflow/tensorflow:latest-gpu-jupyter\n",
    "#jupyter notebook\n",
    "\n",
    "#!pip install lambeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import BobcatParser, TreeReader, TreeReaderMode, spiders_reader, cups_reader, stairs_reader\n",
    "from lambeq import TensorAnsatz, SpiderAnsatz, MPSAnsatz, AtomicType\n",
    "from discopy import Dim\n",
    "from classic_pipeline import *\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define atomic-types\n",
    "\n",
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "C = AtomicType.CONJUNCTION\n",
    "P = AtomicType.PUNCTUATION\n",
    "NP = AtomicType.NOUN_PHRASE\n",
    "PP = AtomicType.PREPOSITIONAL_PHRASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser declaration\n",
    "\n",
    "bobcat_parser = BobcatParser(verbose = \"progress\")\n",
    "spider_parser = spiders_reader\n",
    "cups_parser = cups_reader\n",
    "stairs_parser = stairs_reader\n",
    "tree_parser = TreeReader(mode=TreeReaderMode.RULE_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ansatze declaration\n",
    "\n",
    "tensor_ansatz = TensorAnsatz({N: Dim(2), S: Dim(2), C: Dim(2), P: Dim(2), NP: Dim(2), PP: Dim(2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data-extraction for classic pipeline (linux)\n",
    "\n",
    "pip = ClassicPipeline(bobcat_parser, tensor_ansatz)\n",
    "pip.add_rewriter_rules(ClassicPipeline.SUPPORTED_RULES[0], ClassicPipeline.SUPPORTED_RULES[1], ClassicPipeline.SUPPORTED_RULES[4])\n",
    "train_labels, train_circuits = pip.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/GPS_edited.csv\", \"n\")\n",
    "test_labels, test_circuits = pip.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/CPN_edited.csv\", \"n\")\n",
    "eval_labels, eval_circuits = pip.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/ePurse_edited.csv\", \"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data-extraction for classic pipeline (win11)\n",
    "\n",
    "pip = ClassicPipeline(bobcat_parser, tensor_ansatz)\n",
    "pip.add_rewriter_rules(ClassicPipeline.SUPPORTED_RULES[0], ClassicPipeline.SUPPORTED_RULES[1], ClassicPipeline.SUPPORTED_RULES[4])\n",
    "train_labels, train_circuits = pip.create_circuits_and_labels(\"C:\\\\Users\\\\calif\\\\Documents\\\\GitHub\\\\Tesi-Quantum-NLP\\\\project\\\\datasets\\\\edited_datasets\\\\GPS_edited.csv\", \"n\")\n",
    "test_labels, test_circuits = pip.create_circuits_and_labels(\"C:\\\\Users\\\\calif\\\\Documents\\\\GitHub\\\\Tesi-Quantum-NLP\\\\project\\\\datasets\\\\edited_datasets\\\\CPN_edited.csv\", \"n\")\n",
    "eval_labels, eval_circuits = pip.create_circuits_and_labels(\"C:\\\\Users\\\\calif\\\\Documents\\\\GitHub\\\\Tesi-Quantum-NLP\\\\project\\\\datasets\\\\edited_datasets\\\\ePurse_edited.csv\", \"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(\"train_data.txt\", train_labels, train_circuits)\n",
    "save_data(\"test_data.txt\", test_labels, test_circuits)\n",
    "save_data(\"eval_data.txt\", eval_labels, eval_circuits)\n",
    "\n",
    "#train_labels, train_circuits = load_data(\"train_data.txt\")\n",
    "#test_labels, test_circuits = load_data(\"test_data.txt\")\n",
    "#eval_labels, eval_circuits = load_data(\"eval_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training block for classical pipeline\n",
    "\n",
    "train_set, test_set = pip.create_dataset(train_labels[0:], train_circuits[0:]), pip.create_dataset(test_labels[0:], test_circuits[0:])\n",
    "pip.create_trainer(train_circuits[0:], test_circuits[0:])\n",
    "pip.train_model(train_set, test_set)\n",
    "pip.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PytorchModel.from_checkpoint(checkpoint_path = \"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/codice/runs/May09_15-04-56_archlinux/model.lt\")\n",
    "#model = PytorchModel.load(checkpoint_path = \"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/codice/runs/May09_15-04-56_archlinux/model.lt\")\n",
    "trainer = PytorchTrainer(\n",
    "                model = model,\n",
    "                loss_function = torch.nn.BCEWithLogitsLoss(),\n",
    "                optimizer = torch.optim.AdamW,\n",
    "                epochs = 70,\n",
    "                evaluate_functions = eval_metrics,\n",
    "                evaluate_on_train = True,\n",
    "                learning_rate = LEARNING_RATE,\n",
    "                verbose = \"text\",\n",
    "                seed = CLASSIC_SEED\n",
    "        )\n",
    "\n",
    "train_set, test_set = pip.create_dataset(train_labels[128:], train_circuits[128:]), pip.create_dataset(test_labels[128:], test_circuits[128:])\n",
    "trainer.fit(train_set, test_set, evaluation_step = 1, logging_step = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "for pos, diagram in enumerate(train_circuits):\n",
    "    key = pos\n",
    "    if temp_dict.get(key) == None:\n",
    "        temp_dict[key] = len(diagram)\n",
    "    else:\n",
    "        temp_dict[key] += 1\n",
    "        \n",
    "train_dict = temp_dict\n",
    "for key, val in train_dict.items():\n",
    "    print(f\"{key}   {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "for diagram in test_circuits:\n",
    "    key = len(diagram)\n",
    "    if temp_dict.get(key) == None:\n",
    "        temp_dict[key] = 1\n",
    "    else:\n",
    "        temp_dict[key] += 1\n",
    "        \n",
    "test_dict = dict(sorted(temp_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "for diagram in eval_circuits:\n",
    "    key = len(diagram)\n",
    "    if temp_dict.get(key) == None:\n",
    "        temp_dict[key] = 1\n",
    "    else:\n",
    "        temp_dict[key] += 1\n",
    "        \n",
    "eval_dict = dict(sorted(temp_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensors = []\n",
    "test_tensors = []\n",
    "\n",
    "for circuit in train_circuits:\n",
    "    symbols = set(circuit.free_symbols)\n",
    "    symbol2index = {symbol: i for i, symbol in enumerate(symbols)}\n",
    "\n",
    "    N = len(symbols)\n",
    "    matrix = np.zeros((N, N), dtype=bool)\n",
    "    for i, symbol_i in enumerate(symbols):\n",
    "        for j, symbol_j in enumerate(symbols):\n",
    "            if any(box.dom == symbol_i and box.cod == symbol_j for box in circuit.boxes):\n",
    "                matrix[i, j] = True\n",
    "\n",
    "    tensor = torch.tensor(np.stack([matrix, matrix], axis=-1), dtype=torch.bool)\n",
    "    train_tensors.append(tensor)\n",
    "\n",
    "for circuit in test_circuits:\n",
    "    symbols = set(circuit.free_symbols)\n",
    "    symbol2index = {symbol: i for i, symbol in enumerate(symbols)}\n",
    "\n",
    "    N = len(symbols)\n",
    "    matrix = np.zeros((N, N), dtype=bool)\n",
    "    for i, symbol_i in enumerate(symbols):\n",
    "        for j, symbol_j in enumerate(symbols):\n",
    "            if any(box.dom == symbol_i and box.cod == symbol_j for box in circuit.boxes):\n",
    "                matrix[i, j] = True\n",
    "\n",
    "    tensor = torch.tensor(np.stack([matrix, matrix], axis=-1), dtype=torch.bool)\n",
    "    test_tensors.append(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import BobcatParser, AtomicType\n",
    "from lambeq import TensorAnsatz\n",
    "from discopy import Box, Ty, Dim, Word\n",
    "# Define atomic types\n",
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "\n",
    "sentence = 'John walks in the park'\n",
    "\n",
    "# Get a string diagram\n",
    "parser = BobcatParser(verbose='text')\n",
    "tensor_ansatz = TensorAnsatz({N: Dim(2), S: Dim(2)})\n",
    "diagram = parser.sentence2diagram(sentence)\n",
    "tensor_diagram = tensor_ansatz(diagram)\n",
    "\n",
    "\n",
    "pad_diagrams = [tensor_ansatz(parser.sentence2diagram(\"parola\")) for i in range(1, 20)]\n",
    "\n",
    "new_diagram = tensor_diagram\n",
    "for pad in pad_diagrams:\n",
    "    new_diagram = pad @ new_diagram\n",
    "\n",
    "print(new_diagram)\n",
    "print(len(new_diagram))\n",
    "print(len(tensor_diagram))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
