{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo docker run --gpus all -p 8888:8888 -it --rm tensorflow/tensorflow:latest-gpu-jupyter\n",
    "#jupyter notebook\n",
    "\n",
    "#!pip install lambeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriano22_/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from lambeq import BobcatParser, TreeReader, TreeReaderMode, spiders_reader, cups_reader, stairs_reader\n",
    "from lambeq import TensorAnsatz, SpiderAnsatz, MPSAnsatz, AtomicType\n",
    "from discopy import Dim\n",
    "from classic_pipeline import *\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define atomic-types\n",
    "\n",
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "C = AtomicType.CONJUNCTION\n",
    "P = AtomicType.PUNCTUATION\n",
    "NP = AtomicType.NOUN_PHRASE\n",
    "PP = AtomicType.PREPOSITIONAL_PHRASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser declaration\n",
    "\n",
    "bobcat_parser = BobcatParser(verbose = \"progress\")\n",
    "spider_parser = spiders_reader\n",
    "cups_parser = cups_reader\n",
    "stairs_parser = stairs_reader\n",
    "tree_parser = TreeReader(mode=TreeReaderMode.RULE_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ansatze declaration\n",
    "\n",
    "tensor_ansatz = TensorAnsatz({N: Dim(2), S: Dim(2), C: Dim(2), P: Dim(2), NP: Dim(2), PP: Dim(2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data-extraction for classic pipeline\n",
    "\n",
    "pip = ClassicPipeline(bobcat_parser, tensor_ansatz)\n",
    "pip.add_rewriter_rules(ClassicPipeline.SUPPORTED_RULES[0], ClassicPipeline.SUPPORTED_RULES[1], ClassicPipeline.SUPPORTED_RULES[4])\n",
    "train_labels, train_circuits = pip.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/GPS_edited.csv\", \"n\")\n",
    "test_labels, test_circuits = pip.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/CPN_edited.csv\", \"n\")\n",
    "eval_labels, eval_circuits = pip.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/ePurse_edited.csv\", \"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(\"train_data.txt\", train_labels, train_circuits)\n",
    "save_data(\"test_data.txt\", test_labels, test_circuits)\n",
    "save_data(\"eval_data.txt\", eval_labels, eval_circuits)\n",
    "\n",
    "#train_labels, train_circuits = load_data(\"train_data.txt\")\n",
    "#test_labels, test_circuits = load_data(\"test_data.txt\")\n",
    "#eval_labels, eval_circuits = load_data(\"eval_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18   1\n",
      "20   2\n",
      "21   3\n",
      "23   2\n",
      "24   1\n",
      "25   2\n",
      "26   1\n",
      "27   2\n",
      "29   2\n",
      "30   2\n",
      "31   5\n",
      "32   4\n",
      "33   3\n",
      "34   2\n",
      "35   2\n",
      "36   3\n",
      "37   3\n",
      "38   3\n",
      "39   2\n",
      "40   4\n",
      "42   2\n",
      "43   2\n",
      "44   2\n",
      "45   6\n",
      "46   1\n",
      "47   2\n",
      "48   8\n",
      "49   4\n",
      "50   2\n",
      "51   3\n",
      "52   4\n",
      "53   1\n",
      "54   3\n",
      "57   4\n",
      "58   4\n",
      "59   2\n",
      "60   2\n",
      "61   2\n",
      "62   1\n",
      "65   3\n",
      "66   1\n",
      "68   1\n",
      "70   1\n",
      "72   2\n",
      "73   1\n",
      "74   1\n",
      "75   3\n",
      "76   2\n",
      "79   2\n",
      "82   1\n",
      "83   2\n",
      "89   1\n",
      "90   1\n",
      "94   2\n",
      "95   1\n",
      "98   2\n",
      "100   1\n",
      "101   1\n",
      "102   1\n",
      "103   2\n",
      "104   1\n",
      "106   1\n",
      "107   1\n",
      "113   1\n",
      "115   1\n",
      "118   3\n",
      "122   1\n",
      "126   1\n",
      "127   2\n",
      "132   1\n",
      "140   1\n",
      "156   4\n",
      "161   1\n",
      "170   1\n",
      "171   2\n",
      "180   1\n",
      "181   2\n",
      "187   1\n",
      "189   1\n",
      "195   2\n",
      "197   1\n",
      "218   1\n",
      "276   1\n"
     ]
    }
   ],
   "source": [
    "temp_dict = {}\n",
    "for diagram in train_circuits:\n",
    "    key = len(diagram)\n",
    "    if temp_dict.get(key) == None:\n",
    "        temp_dict[key] = 1\n",
    "    else:\n",
    "        temp_dict[key] += 1\n",
    "        \n",
    "train_dict = dict(sorted(temp_dict.items()))\n",
    "for key, val in train_dict.items():\n",
    "    print(f\"{key}   {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "for diagram in test_circuits:\n",
    "    key = len(diagram)\n",
    "    if temp_dict.get(key) == None:\n",
    "        temp_dict[key] = 1\n",
    "    else:\n",
    "        temp_dict[key] += 1\n",
    "        \n",
    "test_dict = dict(sorted(temp_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "for diagram in eval_circuits:\n",
    "    key = len(diagram)\n",
    "    if temp_dict.get(key) == None:\n",
    "        temp_dict[key] = 1\n",
    "    else:\n",
    "        temp_dict[key] += 1\n",
    "        \n",
    "eval_dict = dict(sorted(temp_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training block for classical pipeline\n",
    "\n",
    "train_set, test_set = pip.create_dataset(train_labels, train_circuits), pip.create_dataset(test_labels, test_circuits)\n",
    "pip.create_trainer(train_circuits, test_circuits)\n",
    "pip.train_model(train_set, test_set)\n",
    "pip.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensors = []\n",
    "test_tensors = []\n",
    "\n",
    "for circuit in train_circuits:\n",
    "    symbols = set(circuit.free_symbols)\n",
    "    symbol2index = {symbol: i for i, symbol in enumerate(symbols)}\n",
    "\n",
    "    N = len(symbols)\n",
    "    matrix = np.zeros((N, N), dtype=bool)\n",
    "    for i, symbol_i in enumerate(symbols):\n",
    "        for j, symbol_j in enumerate(symbols):\n",
    "            if any(box.dom == symbol_i and box.cod == symbol_j for box in circuit.boxes):\n",
    "                matrix[i, j] = True\n",
    "\n",
    "    tensor = torch.tensor(np.stack([matrix, matrix], axis=-1), dtype=torch.bool)\n",
    "    train_tensors.append(tensor)\n",
    "\n",
    "for circuit in test_circuits:\n",
    "    symbols = set(circuit.free_symbols)\n",
    "    symbol2index = {symbol: i for i, symbol in enumerate(symbols)}\n",
    "\n",
    "    N = len(symbols)\n",
    "    matrix = np.zeros((N, N), dtype=bool)\n",
    "    for i, symbol_i in enumerate(symbols):\n",
    "        for j, symbol_j in enumerate(symbols):\n",
    "            if any(box.dom == symbol_i and box.cod == symbol_j for box in circuit.boxes):\n",
    "                matrix[i, j] = True\n",
    "\n",
    "    tensor = torch.tensor(np.stack([matrix, matrix], axis=-1), dtype=torch.bool)\n",
    "    test_tensors.append(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import BobcatParser, AtomicType\n",
    "from lambeq import TensorAnsatz\n",
    "from discopy import Box, Ty, Dim, Word\n",
    "# Define atomic types\n",
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "\n",
    "sentence = 'John walks in the park'\n",
    "\n",
    "# Get a string diagram\n",
    "parser = BobcatParser(verbose='text')\n",
    "tensor_ansatz = TensorAnsatz({N: Dim(2), S: Dim(2)})\n",
    "diagram = parser.sentence2diagram(sentence)\n",
    "tensor_diagram = tensor_ansatz(diagram)\n",
    "\n",
    "\n",
    "pad_diagrams = [tensor_ansatz(parser.sentence2diagram(\"parola\")) for i in range(1, 20)]\n",
    "\n",
    "new_diagram = tensor_diagram\n",
    "for pad in pad_diagrams:\n",
    "    new_diagram = pad @ new_diagram\n",
    "\n",
    "print(new_diagram)\n",
    "print(len(new_diagram))\n",
    "print(len(tensor_diagram))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
