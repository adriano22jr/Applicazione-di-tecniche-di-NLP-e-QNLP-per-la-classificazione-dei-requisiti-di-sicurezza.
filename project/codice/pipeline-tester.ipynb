{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriano22_/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from lambeq import BobcatParser, TreeReader, TreeReaderMode, spiders_reader, cups_reader, stairs_reader\n",
    "from lambeq import TensorAnsatz, SpiderAnsatz, MPSAnsatz, AtomicType\n",
    "from discopy import Dim\n",
    "from classic_pipeline import *\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define atomic-types\n",
    "\n",
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "C = AtomicType.CONJUNCTION\n",
    "P = AtomicType.PUNCTUATION\n",
    "NP = AtomicType.NOUN_PHRASE\n",
    "PP = AtomicType.PREPOSITIONAL_PHRASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser declaration\n",
    "\n",
    "bobcat_parser = BobcatParser(verbose = \"progress\")\n",
    "spider_parser = spiders_reader\n",
    "cups_parser = cups_reader\n",
    "stairs_parser = stairs_reader\n",
    "tree_parser = TreeReader(mode=TreeReaderMode.RULE_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ansatze declaration\n",
    "\n",
    "tensor_ansatz = TensorAnsatz({N: Dim(2), S: Dim(2), C: Dim(2), P: Dim(2), NP: Dim(2), PP: Dim(2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data-extraction for classic pipeline (linux)\n",
    "\n",
    "pip = ClassicPipeline(bobcat_parser, tensor_ansatz)\n",
    "pip.add_rewriter_rules(ClassicPipeline.SUPPORTED_RULES[0], ClassicPipeline.SUPPORTED_RULES[1], ClassicPipeline.SUPPORTED_RULES[4])\n",
    "#train_labels, train_circuits = pip.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/GPS_edited.csv\", \"n\")\n",
    "#test_labels, test_circuits = pip.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/CPN_edited.csv\", \"n\")\n",
    "#eval_labels, eval_circuits = pip.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/ePurse_edited.csv\", \"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data-extraction for classic pipeline (win11)\n",
    "\n",
    "pip = ClassicPipeline(bobcat_parser, tensor_ansatz)\n",
    "pip.add_rewriter_rules(ClassicPipeline.SUPPORTED_RULES[0], ClassicPipeline.SUPPORTED_RULES[1], ClassicPipeline.SUPPORTED_RULES[4])\n",
    "train_labels, train_circuits = pip.create_circuits_and_labels(\"C:\\\\Users\\\\calif\\\\Documents\\\\GitHub\\\\Tesi-Quantum-NLP\\\\project\\\\datasets\\\\edited_datasets\\\\GPS_edited.csv\", \"n\")\n",
    "test_labels, test_circuits = pip.create_circuits_and_labels(\"C:\\\\Users\\\\calif\\\\Documents\\\\GitHub\\\\Tesi-Quantum-NLP\\\\project\\\\datasets\\\\edited_datasets\\\\CPN_edited.csv\", \"n\")\n",
    "eval_labels, eval_circuits = pip.create_circuits_and_labels(\"C:\\\\Users\\\\calif\\\\Documents\\\\GitHub\\\\Tesi-Quantum-NLP\\\\project\\\\datasets\\\\edited_datasets\\\\ePurse_edited.csv\", \"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_data(\"train_data.txt\", train_labels, train_circuits)\n",
    "#save_data(\"test_data.txt\", test_labels, test_circuits)\n",
    "#save_data(\"eval_data.txt\", eval_labels, eval_circuits)\n",
    "\n",
    "train_labels, train_circuits = load_data(\"train_data.txt\")\n",
    "test_labels, test_circuits = load_data(\"test_data.txt\")\n",
    "eval_labels, eval_circuits = load_data(\"eval_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-set (GPS) faulty entries: 127:128 128:129 129:130 136:137 137:138 138:139 147:148 150:151 151:152 155:156 156:157\n",
    "#test-set (CPN) faulty entries: None\n",
    "#eval-set (ePurse) faulty entries: 22:23 34:46\n",
    "\n",
    "\n",
    "rtrain_circuits = train_circuits[0:127] + train_circuits[130:136] + train_circuits[139:147] + train_circuits[148:150] + train_circuits[152:155] + train_circuits[157:]\n",
    "reval_circuits = eval_circuits[0:22] + eval_circuits[23:34] + eval_circuits[46:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training block for classical pipeline\n",
    "\n",
    "train_set, test_set, eval_set = pip.create_dataset(train_labels[0:157], rtrain_circuits), pip.create_dataset(test_labels, test_circuits), pip.create_dataset(eval_labels[0:111], reval_circuits)\n",
    "pip.create_trainer(rtrain_circuits, test_circuits, reval_circuits)\n",
    "pip.train_model(train_set, eval_set)\n",
    "pip.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensors = []\n",
    "test_tensors = []\n",
    "\n",
    "for circuit in train_circuits:\n",
    "    symbols = set(circuit.free_symbols)\n",
    "    symbol2index = {symbol: i for i, symbol in enumerate(symbols)}\n",
    "\n",
    "    N = len(symbols)\n",
    "    matrix = np.zeros((N, N), dtype=bool)\n",
    "    for i, symbol_i in enumerate(symbols):\n",
    "        for j, symbol_j in enumerate(symbols):\n",
    "            if any(box.dom == symbol_i and box.cod == symbol_j for box in circuit.boxes):\n",
    "                matrix[i, j] = True\n",
    "\n",
    "    tensor = torch.tensor(np.stack([matrix, matrix], axis=-1), dtype=torch.bool)\n",
    "    train_tensors.append(tensor)\n",
    "\n",
    "for circuit in test_circuits:\n",
    "    symbols = set(circuit.free_symbols)\n",
    "    symbol2index = {symbol: i for i, symbol in enumerate(symbols)}\n",
    "\n",
    "    N = len(symbols)\n",
    "    matrix = np.zeros((N, N), dtype=bool)\n",
    "    for i, symbol_i in enumerate(symbols):\n",
    "        for j, symbol_j in enumerate(symbols):\n",
    "            if any(box.dom == symbol_i and box.cod == symbol_j for box in circuit.boxes):\n",
    "                matrix[i, j] = True\n",
    "\n",
    "    tensor = torch.tensor(np.stack([matrix, matrix], axis=-1), dtype=torch.bool)\n",
    "    test_tensors.append(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import BobcatParser, AtomicType\n",
    "from lambeq import TensorAnsatz\n",
    "from discopy import Box, Ty, Dim, Word\n",
    "# Define atomic types\n",
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "\n",
    "sentence = 'John walks in the park'\n",
    "\n",
    "# Get a string diagram\n",
    "parser = BobcatParser(verbose='text')\n",
    "tensor_ansatz = TensorAnsatz({N: Dim(2), S: Dim(2)})\n",
    "diagram = parser.sentence2diagram(sentence)\n",
    "tensor_diagram = tensor_ansatz(diagram)\n",
    "\n",
    "\n",
    "pad_diagrams = [tensor_ansatz(parser.sentence2diagram(\"parola\")) for i in range(1, 20)]\n",
    "\n",
    "new_diagram = tensor_diagram\n",
    "for pad in pad_diagrams:\n",
    "    new_diagram = pad @ new_diagram\n",
    "\n",
    "print(new_diagram)\n",
    "print(len(new_diagram))\n",
    "print(len(tensor_diagram))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
