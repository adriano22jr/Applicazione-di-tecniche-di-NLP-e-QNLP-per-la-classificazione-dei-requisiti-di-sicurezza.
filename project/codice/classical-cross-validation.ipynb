{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import BobcatParser, cups_reader, stairs_reader\n",
    "from lambeq import TensorAnsatz, SpiderAnsatz, MPSAnsatz, AtomicType\n",
    "from discopy import Dim\n",
    "from classic_pipeline import *\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "C = AtomicType.CONJUNCTION\n",
    "P = AtomicType.PUNCTUATION\n",
    "NP = AtomicType.NOUN_PHRASE\n",
    "PP = AtomicType.PREPOSITIONAL_PHRASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_ansatz = TensorAnsatz({N: Dim(2), S: Dim(2), C: Dim(2), P: Dim(2), NP: Dim(2), PP: Dim(2)})\n",
    "spider_ansatz = SpiderAnsatz({N: Dim(2), S: Dim(2), C: Dim(2), P: Dim(2), NP: Dim(2), PP: Dim(2)})\n",
    "mps_ansatz = MPSAnsatz({N: Dim(2), S: Dim(2), C: Dim(2), P: Dim(2), NP: Dim(2), PP: Dim(2)}, bond_dim = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ClassicPipeline(stairs_reader, tensor_ansatz)\n",
    "#gps_labels, gps_circuits = pipeline.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/classical/GPS.csv\", \"n\")\n",
    "#cpn_labels, cpn_circuits = pipeline.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/classical/CPN.csv\", \"n\")\n",
    "#purse_labels, epurse_circuits = pipeline.create_circuits_and_labels(\"/home/adriano22_/Documents/GitHub/Tesi-Quantum-NLP/project/datasets/edited_datasets/classical/ePurse.csv\", \"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_data(\"gps_data.txt\", gps_labels, gps_circuits)\n",
    "#save_data(\"cpn_data.txt\", cpn_labels, cpn_circuits)\n",
    "#save_data(\"epurse_data.txt\", epurse_labels, epurse_circuits)\n",
    "\n",
    "gps_labels, gps_circuits = load_data(\"gps_data.txt\")\n",
    "cpn_labels, cpn_circuits = load_data(\"cpn_data.txt\")\n",
    "epurse_labels, epurse_circuits = load_data(\"epurse_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-fold cross validation for gps dataset\n",
    "gps_folds = k_split(gps_circuits, gps_labels, 5)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    print(f\"Running fold {i} of 5:\")\n",
    "    train_set, test_set = pipeline.fold_datasets(gps_folds, 1)\n",
    "\n",
    "    circuits = []\n",
    "    for item in gps_folds:\n",
    "        circuits += [item[j][0] for j in range(len(item))]\n",
    "\n",
    "    model = pipeline.create_model(circuits)\n",
    "    pipeline.create_trainer(model = model, loss = torch.nn.BCEWithLogitsLoss(), optimizer = torch.optim.AdamW, n_epochs = 100, lr = 3e-2)\n",
    "    pipeline.train_model(train_set, test_set, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-fold cross validation for cpn dataset\n",
    "cpn_folds = k_split(cpn_circuits, cpn_labels, 5)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    print(f\"Running fold {i} of 5:\")\n",
    "    train_set, test_set = pipeline.fold_datasets(cpn_folds, 1)\n",
    "\n",
    "    circuits = []\n",
    "    for item in cpn_folds:\n",
    "        circuits += [item[j][0] for j in range(len(item))]\n",
    "\n",
    "    model = pipeline.create_model(circuits)\n",
    "    pipeline.create_trainer(model = model, loss = torch.nn.BCEWithLogitsLoss(), optimizer = torch.optim.AdamW, n_epochs = 100, lr = 3e-2)\n",
    "    pipeline.train_model(train_set, test_set, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-fold cross validation for epurse dataset\n",
    "epurse_folds = k_split(epurse_circuits, epurse_labels, 5)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    print(f\"Running fold {i} of 5:\")\n",
    "    train_set, test_set = pipeline.fold_datasets(epurse_folds, 1)\n",
    "\n",
    "    circuits = []\n",
    "    for item in epurse_folds:\n",
    "        circuits += [item[j][0] for j in range(len(item))]\n",
    "\n",
    "    model = pipeline.create_model(circuits)\n",
    "    pipeline.create_trainer(model = model, loss = torch.nn.BCEWithLogitsLoss(), optimizer = torch.optim.AdamW, n_epochs = 100, lr = 3e-2)\n",
    "    pipeline.train_model(train_set, test_set, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-fold cross validation for cpn_gps dataset\n",
    "cpn_gps_folds = k_split(cpn_circuits + gps_circuits, cpn_labels + gps_labels, 5)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    print(f\"Running fold {i} of 5:\")\n",
    "    train_set, test_set = pipeline.fold_datasets(cpn_gps_folds, 1)\n",
    "\n",
    "    circuits = []\n",
    "    for item in cpn_gps_folds:\n",
    "        circuits += [item[j][0] for j in range(len(item))]\n",
    "\n",
    "    model = pipeline.create_model(circuits)\n",
    "    pipeline.create_trainer(model = model, loss = torch.nn.BCEWithLogitsLoss(), optimizer = torch.optim.AdamW, n_epochs = 100, lr = 3e-2)\n",
    "    pipeline.train_model(train_set, test_set, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-fold cross validation for cpn_epurse dataset\n",
    "cpn_epurse_folds = k_split(cpn_circuits + epurse_circuits, cpn_labels + epurse_labels, 5)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    print(f\"Running fold {i} of 5:\")\n",
    "    train_set, test_set = pipeline.fold_datasets(cpn_epurse_folds, 1)\n",
    "\n",
    "    circuits = []\n",
    "    for item in cpn_epurse_folds:\n",
    "        circuits += [item[j][0] for j in range(len(item))]\n",
    "\n",
    "    model = pipeline.create_model(circuits)\n",
    "    pipeline.create_trainer(model = model, loss = torch.nn.BCEWithLogitsLoss(), optimizer = torch.optim.AdamW, n_epochs = 100, lr = 3e-2)\n",
    "    pipeline.train_model(train_set, test_set, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-fold cross validation for gps_epurse dataset\n",
    "gps_epurse_folds = k_split(gps_circuits + epurse_circuits, gps_labels + epurse_labels, 5)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    print(f\"Running fold {i} of 5:\")\n",
    "    train_set, test_set = pipeline.fold_datasets(gps_epurse_folds, 1)\n",
    "\n",
    "    circuits = []\n",
    "    for item in gps_epurse_folds:\n",
    "        circuits += [item[j][0] for j in range(len(item))]\n",
    "\n",
    "    model = pipeline.create_model(circuits)\n",
    "    pipeline.create_trainer(model = model, loss = torch.nn.BCEWithLogitsLoss(), optimizer = torch.optim.AdamW, n_epochs = 100, lr = 3e-2)\n",
    "    pipeline.train_model(train_set, test_set, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-fold cross validation for all dataset\n",
    "all_folds = k_split(cpn_circuits + gps_circuits + epurse_circuits, cpn_labels + gps_labels + epurse_labels, 5)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    print(f\"Running fold {i} of 5:\")\n",
    "    train_set, test_set = pipeline.fold_datasets(all_folds, 1)\n",
    "\n",
    "    circuits = []\n",
    "    for item in all_folds:\n",
    "        circuits += [item[j][0] for j in range(len(item))]\n",
    "\n",
    "    model = pipeline.create_model(circuits)\n",
    "    pipeline.create_trainer(model = model, loss = torch.nn.BCEWithLogitsLoss(), optimizer = torch.optim.AdamW, n_epochs = 100, lr = 3e-2)\n",
    "    pipeline.train_model(train_set, test_set, 1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
